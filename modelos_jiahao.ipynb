{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c02b6d0",
   "metadata": {},
   "source": [
    "# Modelos CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95b581",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "425e3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from improved_model import ImprovedCNNModel as  ElVostreModel # Assuming you have an improved model defined in this module\n",
    "# Paralelize the model\n",
    "import multiprocessing\n",
    "# Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e00d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "76fd0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade este código después de cargar el dataset pero antes de crear el dataloader\n",
    "def undersample_dataset(dataset, random_seed=123):\n",
    "    # Asegurar reproducibilidad\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    # Contar muestras por clase\n",
    "    class_indices = {}\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        if label not in class_indices:\n",
    "            class_indices[label] = []\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    # Encontrar la clase con menos muestras\n",
    "    min_class_count = min([len(indices) for indices in class_indices.values()])\n",
    "    print(f\"Clase minoritaria: {min_class_count} muestras\")\n",
    "    \n",
    "    # Seleccionar muestras para el dataset balanceado\n",
    "    balanced_indices = []\n",
    "    for label, indices in class_indices.items():\n",
    "        # Seleccionar aleatoriamente min_class_count muestras\n",
    "        selected = random.sample(indices, min_class_count)\n",
    "        balanced_indices.extend(selected)\n",
    "    \n",
    "    print(f\"Dataset original: {len(dataset)} muestras → Dataset balanceado: {len(balanced_indices)} muestras\")\n",
    "    \n",
    "    # Crear un subconjunto del dataset\n",
    "    return Subset(dataset, balanced_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "003abb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "# Transforma para entrenamiento (con data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "# Transforma para validación (sin augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "data_dir = \"data/train\"\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=train_transform)\n",
    "\n",
    "class_names = dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Aplicar balanceo SOLO al dataset de entrenamiento\n",
    "# dataset = undersample_dataset(dataset)\n",
    "\n",
    "# ---------- Validació ----------\n",
    "val_dir = \"data/validation\"\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=val_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a9451207",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batch_size = 64\n",
    "max_total_time = 1800 \n",
    "num_core = multiprocessing.cpu_count()\n",
    "weight_decay = 1e-4\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=True, \n",
    "                        num_workers=num_core-1,\n",
    "                        persistent_workers=True,\n",
    "                        prefetch_factor=4)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=num_core-1,\n",
    "                        persistent_workers=True,\n",
    "                        prefetch_factor=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "641404d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Model ----------\n",
    "class ElVostreModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ElVostreModel, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # Bloque 1: 28×28 → 14×14\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Bloque 2: 14×14 → 7×7\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Bloque 3: 7×7 → 3×3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 3 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256), \n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4bef1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = ElVostreModel(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fe1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# Añadir el scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, \n",
    "                              mode='max', \n",
    "                              factor=0.1, \n",
    "                              patience=1,\n",
    "                              threshold=0.01\n",
    "                              )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dc15691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, name):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"{name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4cf4fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 1[152.14s]) Accuracy: 60.87%\n",
      "Nou millor model guardat amb 60.87% de precisió de validació\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 2[109.23s]) Accuracy: 59.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 3[102.21s]) Accuracy: 63.77%\n",
      "Nou millor model guardat amb 63.77% de precisió de validació\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 4[101.08s]) Accuracy: 57.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 5[101.03s]) Accuracy: 64.49%\n",
      "Nou millor model guardat amb 64.49% de precisió de validació\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 6[100.50s]) Accuracy: 63.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 7[101.86s]) Accuracy: 57.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 8[100.50s]) Accuracy: 67.39%\n",
      "Nou millor model guardat amb 67.39% de precisió de validació\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 9[100.59s]) Accuracy: 68.84%\n",
      "Nou millor model guardat amb 68.84% de precisió de validació\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 10[100.13s]) Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 11[101.60s]) Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 12[103.70s]) Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 13[100.40s]) Accuracy: 67.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 14[98.03s]) Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 15[99.86s]) Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validació (després de la època 16[106.37s]) Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps màxim assolit. Fi de l'entrenament\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "\n",
    "best_val_acc = 0.0\n",
    "model_save_path = \"best_model.pth\"\n",
    "\n",
    "while True:\n",
    "    start_epoch = time.time()\n",
    "    epoch += 1\n",
    "    model.train()\n",
    "    loop = tqdm(dataloader, desc=f\"Època {epoch}\", leave=False)\n",
    "\n",
    "    for i, (images, labels) in enumerate(loop):\n",
    "        if time.time() - start_time > max_total_time-60:\n",
    "            print(\"Temps màxim assolit. Fi de l'entrenament\")\n",
    "            break\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    if time.time() - start_time > max_total_time-60:\n",
    "        break\n",
    "    # Validació per època\n",
    "    val_acc = evaluate(model, val_loader, f\"Validació (després de la època {epoch}[{time.time() - start_epoch:.2f}s])\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Nou millor model guardat amb {best_val_acc * 100:.2f}% de precisió de validació\")\n",
    "    scheduler.step(val_acc)  # Ajusta el LR basado en la precisión de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a450ec",
   "metadata": {},
   "source": [
    "# Final Avaluacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d707a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(path, num_classes):\n",
    "    \"\"\"Carga el mejor modelo guardado.\"\"\"\n",
    "    model = ElVostreModel(num_classes)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "718f879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (subset) Accuracy: 80.38%\n",
      "Validation (final) Accuracy: 68.84%\n",
      "\n",
      "Final Metrics:\n",
      "   Train Accuracy: 80.38%\n",
      "   Validation Accuracy: 68.84%\n",
      "Temps total d'entrenament: 1778.06 segons\n"
     ]
    }
   ],
   "source": [
    "best_model = load_best_model(model_save_path, num_classes)\n",
    "# Evaluar el modelo en el conjunto de entrenamiento y validación\n",
    "train_acc = evaluate(best_model,dataloader, \"Train (subset)\")\n",
    "val_acc = evaluate(best_model, val_loader, \"Validation (final)\")\n",
    "\n",
    "print(f\"\\nFinal Metrics:\")\n",
    "print(f\"   Train Accuracy: {train_acc * 100:.2f}%\")\n",
    "print(f\"   Validation Accuracy: {val_acc * 100:.2f}%\")\n",
    "print(f\"Temps total d'entrenament: {time.time() - start_time:.2f} segons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c388dd",
   "metadata": {},
   "source": [
    "## Afegir els pessos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
